{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the parameters/arguments for ImageDataGenerator class\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,rotation_range=180,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 436 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying ImageDataGenerator functionality to trainset\n",
    "x_train=train_datagen.flow_from_directory(\"d:/Downloads/archive (1)/Dataset/Dataset/train_set\",target_size=(128,128),\n",
    "                                          batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Applying ImageDataGenerator functionality to testset\n",
    "x_test=test_datagen.flow_from_directory(\"d:/Downloads/archive (1)/Dataset/Dataset/test_set\",target_size=(128,128),\n",
    "                                        batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model building libraries\n",
    "\n",
    "#To define Linear initialisation import Sequential\n",
    "from keras.models import Sequential\n",
    "#To add layers import Dense\n",
    "from keras.layers import Dense\n",
    "#To create Convolution kernel import Convolution2D\n",
    "from keras.layers import Convolution2D\n",
    "#import Maxpooling layer\n",
    "from keras.layers import MaxPooling2D\n",
    "#import flatten layer\n",
    "from keras.layers import Flatten\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add convolutional layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))\n",
    "#add maxpooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#add flatten layer \n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add hidden layer\n",
    "model.add(Dense(150,activation='relu'))\n",
    "#add output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure the learning process\n",
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 69s 5s/step - loss: 4.8471 - accuracy: 0.6009 - val_loss: 0.2311 - val_accuracy: 0.9008\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 58s 4s/step - loss: 0.7626 - accuracy: 0.7064 - val_loss: 0.3459 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 63s 5s/step - loss: 0.2958 - accuracy: 0.8693 - val_loss: 0.1277 - val_accuracy: 0.9504\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.2115 - accuracy: 0.9106 - val_loss: 0.1015 - val_accuracy: 0.9752\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 62s 5s/step - loss: 0.1771 - accuracy: 0.9266 - val_loss: 0.0981 - val_accuracy: 0.9587\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 47s 3s/step - loss: 0.1687 - accuracy: 0.9266 - val_loss: 0.0729 - val_accuracy: 0.9835\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 94s 7s/step - loss: 0.1627 - accuracy: 0.9404 - val_loss: 0.0719 - val_accuracy: 0.9835\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 123s 9s/step - loss: 0.1559 - accuracy: 0.9427 - val_loss: 0.0686 - val_accuracy: 0.9835\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 37s 3s/step - loss: 0.1513 - accuracy: 0.9404 - val_loss: 0.0676 - val_accuracy: 0.9835\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 29s 2s/step - loss: 0.1434 - accuracy: 0.9427 - val_loss: 0.0690 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20079e6a8b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_data=x_test,validation_steps=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"forest1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import load_model from keras.model\n",
    "from keras.models import load_model\n",
    "#import image class from keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import cv2\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "model = load_model(\"forest1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img(\"d:/Downloads/archive (1)/Dataset/Dataset/test_set/with fire/180802_CarrFire_010_large_700x467.jpg\")\n",
    "x=image.img_to_array(img)\n",
    "res = cv2.resize(x, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "#expand the image shape\n",
    "x=np.expand_dims(res,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: twilio in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (7.15.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pytz in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from twilio) (2022.6)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from twilio) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from twilio) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from requests>=2.0.0->twilio) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from requests>=2.0.0->twilio) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from requests>=2.0.0->twilio) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (from requests>=2.0.0->twilio) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playsound in c:\\users\\lenovo\\anaconda3\\envs\\tf new\\lib\\site-packages (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import opencv library\n",
    "import cv2\n",
    "#import numpy\n",
    "import numpy as np\n",
    "#import image function from keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "#import load_model from keras\n",
    "from keras.models import load_model\n",
    "#import Client from twilio API\n",
    "from twilio.rest import Client\n",
    "#import playsound package\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved model\n",
    "model=load_model('forest1.h5')\n",
    "#define video\n",
    "video=cv2.VideoCapture(0)\n",
    "#define the features\n",
    "name=['forest','with fire']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "[[1.]]\n",
      "SM391962f57bb65d2e91fa37c193ed9ab5\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "[[1.]]\n",
      "SMe1fa6b15056b9069a71fd680932e5695\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "[[1.]]\n",
      "SM4cf808e8790eb874bd655414b2f14ff8\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "[[1.]]\n",
      "SM68a29384865591a6ad81d2e30ea2e528\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "[[1.]]\n",
      "SM9b024e47ed8497adc5f6ddc9c9bac6f8\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "[[1.]]\n",
      "SMd36138cfc4d76019c8d11fad329628d1\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "[[1.]]\n",
      "SMe5ec32ee98b3824257e1d72f53a3a01d\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "[[1.]]\n",
      "SMe7144946a810cce793b0652b6eea79df\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "[[1.]]\n",
      "SM51ed4ff4cdebefcdb5a2a1c8324c9193\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "[[1.]]\n",
      "SM9289843620211273f1b95ab11204f2c6\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "[[1.]]\n",
      "SM51079c8b98e5f4bae3b68fdfb2c3589f\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "[[1.]]\n",
      "SM7d6480586d5772de412bdcbaef4fa4c4\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 259ms/step\n",
      "[[1.]]\n",
      "SM76c8e0b5918e8e786fea3244eb8998bc\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "[[1.]]\n",
      "SM77942b6b4f67a3d68c126f16de8cfe59\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "[[1.]]\n",
      "SM9a73027e042251d8d31b479dba13bb14\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "[[1.]]\n",
      "SMcf345b30f3c63c9b4e065a66fb68ea0c\n",
      "Fire Detected\n",
      "SMS sent!\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "[[1.]]\n",
      "SM7dea4b8c08f5fd5dd6ef775d12af7128\n",
      "Fire Detected\n",
      "SMS sent!\n"
     ]
    }
   ],
   "source": [
    "#load the saved model\n",
    "model=load_model('forest1.h5')\n",
    "#define video\n",
    "video=cv2.VideoCapture(0)\n",
    "#define the features\n",
    "name=['forest','with fire']\n",
    "while(1):\n",
    "  success,frame=video.read()\n",
    "  cv2.imwrite(\"image.jpg\",frame) \n",
    "  img=image.load_img(\"image.jpg\",target_size=(64,64))\n",
    "  x=image.img_to_array(img)\n",
    "  res = cv2.resize(x, dsize=(128, 128), interpolation=cv2.INTER_CUBIC)\n",
    "  x=np.expand_dims(res,axis=0)\n",
    "  pred=model.predict(x)\n",
    "  p=pred[0]\n",
    "  print(pred)\n",
    "  #cv2.putText(frame,\"predicted class = \"+str(name[p]),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0))\n",
    "  if pred[0]==1:\n",
    "    #twilio account ssid\n",
    "    account_sid='AC4fa9029e52ebfc121fd241042cd0beae'\n",
    "    #twilio account authentication token\n",
    "    auth_token ='b390a07ae967f13a388ea83997e7e476'\n",
    "    client=Client(account_sid,auth_token)\n",
    "\n",
    "    message=client.messages \\\n",
    "    .create(\n",
    "        body='Forest Fire is detected,stay alert',\n",
    "        #use twilio free number\n",
    "        from_='+14247990678',\n",
    "        #to number\n",
    "        to='+918220556970')\n",
    "    print(message.sid)\n",
    "    print('Fire Detected')\n",
    "    print('SMS sent!')\n",
    "    playsound(\"D:/Downloads/72831__audible-edge__tornado-siren-in-streamwood-il.mp3\")\n",
    "  else:\n",
    "    print('No Danger')\n",
    "    #break\n",
    "  cv2.imshow(\"image\",frame)\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "     break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
